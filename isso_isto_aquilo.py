# -*- coding: utf-8 -*-
"""isso-isto-aquilo

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pTF42YpmhTojKCVaUxkdAJvFOkojyZnF
"""

# pegando arquivos do drive
from google.colab import drive
drive.mount('/content/drive')

import re
import pandas as pd

import os

# Initialize an empty list to store dictionaries containing the file number and cleaned text
textList = []

# Traverse through the directory tree starting from the specified path
for root, dirs, files in os.walk("/content/drive/MyDrive/consultorias/isso-isto-aquilo/textos_Daiane"):
    # Iterate over each file in the directory
    for filename in files:
        # Extract the first character of the filename as the file number
        fileNum = filename[:1]

        # Check if the file is a text file
        if filename.endswith('.txt'):
            # Open the file in read mode and read its contents
            with open(os.path.join(root, filename), 'r') as f:
                text = f.read()

                # Clean the text by removing newline characters, tab characters, and multiple consecutive whitespace characters
                textClean = re.sub('\n', '', text)
                textClean = re.sub('\t', '', textClean)
                textClean = re.sub('\s+', ' ', textClean)

                # Append a dictionary to the textList with the file number and cleaned text
                textList.append({'numero': fileNum, 'texto': textClean})

# Function to split text into sentences by punctuation
def split_sentences(text):
    sentences = re.split(r'[.!?;]', text)
    return sentences

data = []  # List to store the extracted data
regex = r'\bisto\b|\bisso\b|\baquilo\b|\bnisto\b|\bdisto\b|\bnisso\b|\bdisso\b|\bnaquilo\b|\bdaquilo\b|\bàquilo\b'
# Iterate over the list of dictionaries
for i in range(len(textList)):
    current_dict = textList[i]
    current_text = current_dict['texto']
    current_numero = current_dict['numero']

    sentences = split_sentences(current_text)
    for j in range(len(sentences)):
        current_sentence = sentences[j]

        # Extract the previous and next sentences if available
        previous_sentence = sentences[j-1] if j > 0 else ''
        next_sentence = sentences[j+1] if j < len(sentences)-1 else ''

        # Find the matching words in the current sentence
        matching_words = re.findall(regex, current_sentence, re.IGNORECASE)

        if len(matching_words) > 0:   
          # Create a dictionary with the extracted data
          extracted_data = {
            'Numero do arquivo': current_numero,
            'Pronome encontrado': " ".join(matching_words),
            'Sentença anterior': previous_sentence,
            'Sentença com pronome': current_sentence,
            'Sentença posterior': next_sentence
            }
          data.append(extracted_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data)

#Exporting
df.to_csv("pronDemonsNeutros22-05-23.csv")
df.to_excel("pronDemonsNeutros22-05-23.xlsx")

df.head()